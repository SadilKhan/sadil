[
    {
        "title": "SHARP Challenge 2023: Solving CAD History and pArameters Recovery from Point clouds and 3D scans. Overview, Datasets, Metrics, and Baselines",
        "authors": " Dimitrios Mallis, Sk Aziz Ali, Elona Dupont, Kseniya Cherenkova, Ahmet Serdar Karadeniz, Mohammad Sadil Khan, Anis Kacem, Gleb Gusev, Djamila Aouada",
        "conference": "ICCV Workshop 2023",
        "year": 2023,
        "codeLink": "https://gitlab.uni.lu/cvi2/iccv2023-sharp-challenge",
        "poster": "https://skazizali.com/assets/pdf/SHARP_ICCV23_Poster.pdf",
        "bibtex": "@inproceedings{AliSHARP_ICCV23,title = {SHARP Challenge 2023: Solving CAD History and pArameters Recovery from Point clouds and 3D scans. Overview, Datasets, Metrics, and Baselines},author = {Mallis, Dimitrios and Ali, Sk Aziz and Dupont, Elona and Cherenkova, Kseniya and Karadeniz, Ahmet Serdar and Kacem, Mohammed Sadil Khan Anis and Gusev, Gleb and Aouada, Djamila},booktitle = {In IEEE/CVF International Conference on Computer Vision (ICCV)},year = {2023},organization = {IEEE},}",
        "arxiv": "https://arxiv.org/abs/2308.07153",
        "dataset": "Recent breakthroughs in geometric Deep Learning (DL) and the availability of large Computer-Aided Design (CAD) datasets have advanced the research on learning CAD modeling processes and relating them to real objects. In this context, 3D reverse engineering of CAD models from 3D scans is considered to be one of the most sought-after goals for the CAD industry. However, recent efforts assume multiple simplifications limiting the applications in real-world settings. The SHARP Challenge 2023 aims at pushing the research a step closer to the real-world scenario of CAD reverse engineering through dedicated datasets and tracks. In this paper, we define the proposed SHARP 2023 tracks, describe the provided datasets, and propose a set of baseline methods along with suitable evaluation metrics to assess the performance of the track solutions. All proposed datasets along with useful routines and the evaluation metrics are publicly available. ",
        "paperLink": "https://paperswithcode.com/paper/sharp-challenge-2023-solving-cad-history-and",
        "categories": "Deep Learning, Computer Vision, Representation Learning, CAD",
        "image": "data/sharp2023.png",
         "metadata": "A large-scale benchmark defining datasets, metrics, and baselines for realistic CAD reverse engineering from 3D scans.",
         "video": ""
    },
    {
        "title": "MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation",
        "authors": "Sankalp Sinha*, Mohammad Sadil Khan*, Muhammad Usama, Shino Sam, Didier Stricker, Sk Aziz Ali, Muhammad Zeshan Afzal",
        "conference": "CVPR 2025",
        "year": 2025,
        "project": "https://sankalpsinha-cmos.github.io/MARVEL/",
        "codeLink": "https://github.com/SadilKhan/MARVEL-FX3D",
        "poster": "data/marvel_poster.png",
        "bibtex": "@InProceedings{Sinha_2025_CVPR, author    = {Sinha, Sankalp and Khan, Mohammad Sadil and Usama, Muhammad and Sam, Shino and Stricker, Didier and Ali, Sk Aziz and Afzal, Muhammad Zeshan},title     = {MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation},booktitle = {Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)}, month     = {June}, year      = {2025},pages     = {8105-8116}}",
        "arxiv": "https://arxiv.org/abs/2411.17945",
        "video": "",
        "dataset": "https://sadilkhan.github.io/Marvel-Explorer/",
        "paperLink": "",
        "categories": "Text-to-3D, Stable Diffusion, 3D Reconstruction, LLM, VLM, Annotation, Objaverse",
        "image": "data/marvel.png",
        "metadata": "Largest 3D captioning dataset (40M+) with domain-specific and multi-level visual reasoning for text-to-3D generation."
    },
    {
        "title": "Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts",
        "authors": "Mohammad Sadil Khan*, Sankalp Sinha*, Sheikh Talha Uddin, Didier Stricker, Sk Aziz Ali, Muhammad Zeshan Afzal",
        "conference": "NeurIPS 2024 (Spotlight)",
        "year": 2024,
        "project": "https://sadilkhan.github.io/text2cad-project/",
        "codeLink": "https://github.com/SadilKhan/Text2CAD",
        "poster": "https://neurips.cc/media/PosterPDFs/NeurIPS%202024/96571.png?t=1731322691.2308366",
        "bibtex": "@inproceedings{khan2024text2cad,author = {Khan, Mohammad Sadil and Sinha, Sankalp and Uddin, Talha and Stricker, Didier and Ali, Sk Aziz and Afzal, Muhammad Zeshan},booktitle = {Advances in Neural Information Processing Systems},editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},pages = {7552--7579},publisher = {Curran Associates, Inc.},title = {Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts},url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/0e5b96f97c1813bb75f6c28532c2ecc7-Paper-Conference.pdf},volume = {37},year = {2024},bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2024/file/0e5b96f97c1813bb75f6c28532c2ecc7-Paper-Conference.pdf}}",
        "arxiv": "https://arxiv.org/abs/2409.17106",
        "video": "",
        "dataset": "https://huggingface.co/datasets/SadilKhan/Text2CAD",
        "paperLink": "https://openreview.net/pdf?id=5k9XeHIK3L",
        "categories": "Deep Learning, Computer Vision, Point Cloud, Representation Learning, Text, LLM, VLM, CAD, Vision-Language Modeling, Annotation",
        "image": "data/text2cad.png",
            "metadata": "First framework that generates CAD design history from natural-language prompts of varying expertise levels."
    },
    {
        "title": "BRep Boundary and Junction Detection for CAD Reverse Engineering",
        "authors": " Sk Aziz Ali, Mohammad Sadil Khan, Didier Stricker",
        "conference": "ICMI 2024",
        "year": 2024,
        "codeLink": "https://github.com/saali14/Scan-to-BRep",
        "project": "https://skazizali.com/brepdetnet.github.io/",
        "poster": "",
        "bibtex": "@INPROCEEDINGS{10585950,author={Ali, Sk Aziz and Khan, Mohammad Sadil and Stricker, Didier},booktitle={2024 IEEE 3rd International Conference on Computing and Machine Intelligence (ICMI)}, title={BRep Boundary and Junction Detection for CAD Reverse Engineering}, year={2024},volume={},number={},pages={1-6},keywords={Training;Solid modeling;Three-dimensional displays;Reverse engineering;Neural networks;Machining;Mechanical systems;BRep;Boundary Detection;Junction Detection;Scan-to-CAD;Reverse Engineering;NMS},doi={10.1109/ICMI60790.2024.10585950}}",
        "arxiv": "https://www.semanticscholar.org/paper/BRep-Boundary-and-Junction-Detection-for-CAD-Ali-Khan/cadccf40d3a254114c75e7c7ab390a0f8ad0bcda",
        "dataset": "",
        "paperLink": "https://ieeexplore.ieee.org/document/10585950",
        "categories": "Deep Learning, Computer Vision, CAD, Brep",
        "image": "data/brep_det_net.png",
        "metadata": "A deep-learning approach for detecting BRep boundaries and junctions to enhance CAD reverse engineering accuracy.",
         "video": ""
    },
    {
        "title": "CAD-SIGNet: CAD Language Inference from Point Clouds using Layer-wise Sketch Instance Guided Attention",
        "authors": "Mohammad Sadil Khan, Elona Dupont, Sk Aziz Ali, Kseniya Cherenkova, Anis Kacem, Djamila Aouada",
        "conference": "CVPR 2024 (Highlight)",
        "year": 2024,
        "project": "http://skazizali.com/cadsignet.github.io/",
        "codeLink": "",
        "poster": "https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30538.png?t=1716992823.610076",
        "bibtex": "@InProceedings{{Khan_2024_CVPR,author = {Khan, Mohammad Sadil and Dupont, Elona and Ali, Sk Aziz and Cherenkova, Kseniya and Kacem, Anis and Aouada, Djamila}, title = {CAD-SIGNet: CAD Language Inference from Point Clouds using Layer-wise Sketch Instance Guided Attention}, booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},month = {June},year = {2024},pages = {4713-4722}}",
        "arxiv": "https://arxiv.org/pdf/2402.17678.pdf",
        "video": "https://www.youtube.com/watch?v=ivg03_ckLIM",
        "dataset": "",
        "paperLink": "https://openaccess.thecvf.com/content/CVPR2024/papers/Khan_CAD-SIGNet_CAD_Language_Inference_from_Point_Clouds_using_Layer-wise_Sketch_CVPR_2024_paper.pdf",
        "categories": "Deep Learning, Computer Vision, Point Cloud, Representation Learning, RandLa-Net, CAD, Vision-Language Modeling",
        "image": "data/cad_signet.png",
        "metadata": "An autoregressive architecture for generating 3D CAD sequence from Point cloud. Uses a novel sketch-guided Attention mechanism."
    }
    
]
