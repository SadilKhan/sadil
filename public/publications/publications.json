[
    {
        "title": "Vignette detection and reconstruction of composed ornaments with a strengthened autoencoder",
        "authors": "Mohammad Sadil Khan , Rémi Emonet , Thierry Fournel",
        "conference": "HAL Priprint",
        "year": 2021,
        "bibtex": "@unpublished{khan:hal-03409930,TITLE = {{Vignette detection and reconstruction of composed ornaments with a strengthened autoencoder}},AUTHOR = {Khan, Mohammad Sadil and Emonet, Remi and Fournel, Thierry},URL = {https://hal.science/hal-03409930},NOTE = {working paper or preprint},YEAR = {2021}, MONTH = Oct,PDF = {https://hal.science/hal-03409930/file/DAE.pdf},HAL_ID = {hal-03409930}, HAL_VERSION = {v1},}",
        "abstract": "A strengthened autoencoder formed by placing an object detector upstream of a decoder is here developed in the context of the model-helped human analysis of composed ornaments from a dictionary of vignettes. The detection part is in charge to detect regions of interest containing some vignette features, and the decoding part to ensure vignette reconstruction with a relative quality depending on feature match. Images of ornaments without typographical composition are generated in order to properly assess the performance of each of the two parts.",
        "paperLink": "https://hal.science/hal-03409930",
        "categories": "Deep Learning, Computer Vision, Object Detection, SSD",
        "image":"data/dae.png"
    },
    {
        "title": "Learning Shapes for Efficient Segmentation of 3D Medical Images using Point Cloud",
        "authors": "Mohammad Sadil Khan, Razmig Kéchichian, Sebastien Valette, Julie Digne",
        "conference": "Master Thesis",
        "year": 2022,
        "codeLink": "https://github.com/SadilKhan/Creatis-Internship",
        "abstract": "In this report, we present a novel approach for 3D medical image segmentation using point clouds. 3D Convolutional Neural Networks have been the most dominating networks in medical image processing but they require large memory footprints and training samples. Hence we used point clouds to represent the image instead of voxels. Point clouds are lightweight and contain shape and smoother surface information. We extracted the point clouds from 3D voxel images using canny edge detection. We modified RandLa-Net, an attention-based point cloud segmentation network with a feature extraction layer to aggregate local geometrical features with spatial point features for our large-scale point cloud segmentation task. Our proposed model performed better than the original network in multi-class as well as binary point cloud segmentation tasks in Visceral dataset. Finally, we propose a model-independent step to perform the image segmentation of the original 3D volumetric images in Visceral dataset by mapping voxels in the point cloud space and adding it to the input point cloud before being passed to the trained model. We performed many experiments on the weights of the Cross-Entropy loss function for the class imbalance problem as well as the intrinsic architectural properties of the model architecture like downsampling factor and distinct latent vector learning that can be improved to perform better segmentation.",
        "paperLink": "data/report.pdf",
        "categories": "Deep Learning, Point Cloud, Representation Learning, RandLa-Net",
        "image":"data/creatis.png"
    },
    {
        "title": "SHARP Challenge 2023: Solving CAD History and pArameters Recovery from Point clouds and 3D scans. Overview, Datasets, Metrics, and Baselines",
        "authors": " Dimitrios Mallis, Sk Aziz Ali, Elona Dupont, Kseniya Cherenkova, Ahmet Serdar Karadeniz, Mohammad Sadil Khan, Anis Kacem, Gleb Gusev, Djamila Aouada",
        "conference": "IEEE/CVF International Conference on Computer Vision (ICCV) workshop (2023)",
        "year": 2023,
        "codeLink": "https://gitlab.uni.lu/cvi2/iccv2023-sharp-challenge",
        "poster": "https://skazizali.com/assets/pdf/SHARP_ICCV23_Poster.pdf",
        "bibtex": "@inproceedings{AliSHARP_ICCV23,title = {SHARP Challenge 2023: Solving CAD History and pArameters Recovery from Point clouds and 3D scans. Overview, Datasets, Metrics, and Baselines},author = {Mallis, Dimitrios and Ali, Sk Aziz and Dupont, Elona and Cherenkova, Kseniya and Karadeniz, Ahmet Serdar and Kacem, Mohammed Sadil Khan Anis and Gusev, Gleb and Aouada, Djamila},booktitle = {In IEEE/CVF International Conference on Computer Vision (ICCV)},year = {2023},organization = {IEEE},}",
        "arxiv": "https://arxiv.org/abs/2308.07153",
        "abstract": "Recent breakthroughs in geometric Deep Learning (DL) and the availability of large Computer-Aided Design (CAD) datasets have advanced the research on learning CAD modeling processes and relating them to real objects. In this context, 3D reverse engineering of CAD models from 3D scans is considered to be one of the most sought-after goals for the CAD industry. However, recent efforts assume multiple simplifications limiting the applications in real-world settings. The SHARP Challenge 2023 aims at pushing the research a step closer to the real-world scenario of CAD reverse engineering through dedicated datasets and tracks. In this paper, we define the proposed SHARP 2023 tracks, describe the provided datasets, and propose a set of baseline methods along with suitable evaluation metrics to assess the performance of the track solutions. All proposed datasets along with useful routines and the evaluation metrics are publicly available. ",
        "paperLink": "https://paperswithcode.com/paper/sharp-challenge-2023-solving-cad-history-and",
        "categories": "Deep Learning, Point Cloud, Representation Learning, RandLa-Net",
        "image": "data/sharp2023.png"
    }
]
