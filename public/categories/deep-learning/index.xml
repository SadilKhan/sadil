<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on Home</title>
    <link>/categories/deep-learning/</link>
    <description>Recent content in Deep Learning on Home</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 28 Jun 2022 00:00:00 +0000</lastBuildDate><atom:link href="/categories/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Part 1 - Point Cloud Introduction</title>
      <link>/blog/pointcloud-series/introduction/</link>
      <pubDate>Wed, 22 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/pointcloud-series/introduction/</guid>
      <description>1. What is Point Cloud? A Point Cloud is a set of points in 3D space which can represent the boundary or the whole object (including inside points). In a point cloud, the points are unordered and are not restricted by any grid which means a point cloud can be expressed in an infinite way (using translation). Each point can have 3D coordinates and feature vectors. $$ P={(X_i,F_i)}^{i=N}_{i=1}, X_i\in\mathbb{R}^3,F_i\in\mathbb{R}^d$$</description>
    </item>
    
    <item>
      <title>Part 2 - Point Cloud Segmentation</title>
      <link>/blog/pointcloud-series/segmentation/</link>
      <pubDate>Tue, 28 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/pointcloud-series/segmentation/</guid>
      <description>Point Cloud Segmentation Methods Point Cloud Segmentation is the task for grouping objects or assigning labels to every points in the point cloud. It is one of the most challenging tasks and a research topic in deep learning since point clouds are noisy, unstructured and lack connectedness property. All the methods are categorized into four categories.
1. Edge Based Methods Edges describe the intrinsic characteristics of the boundary of any 3D object.</description>
    </item>
    
    <item>
      <title>Point Cloud</title>
      <link>/blog/pointcloud-series/</link>
      <pubDate>Tue, 28 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/pointcloud-series/</guid>
      <description>** No content below YAML for the series _index. This file is a leaf bundle, and provides settings for the listing page layout and sidebar content.**</description>
    </item>
    
    <item>
      <title>Learning Shapes for Efficient Segmentation of 3D Medical Images using Point Cloud</title>
      <link>/publications/masterthesis/</link>
      <pubDate>Thu, 23 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>/publications/masterthesis/</guid>
      <description>Abstract In this report, we present a novel approach for 3D medical image segmentation using point clouds. 3D Convolutional Neural Networks have been the most dominating networks in medical image processing but they require large memory footprints and training samples. Hence we used point clouds to represent the image instead of voxels. Point clouds are lightweight and contain shape and smoother surface information. We extracted the point clouds from 3D voxel images using canny edge detection.</description>
    </item>
    
    <item>
      <title>RandLaNet</title>
      <link>/blog/randlanet/</link>
      <pubDate>Thu, 12 May 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/randlanet/</guid>
      <description>Large-Scale Point Cloud Segmentation Network</description>
    </item>
    
    <item>
      <title>Vignette detection and reconstruction of composed ornaments with a strengthened autoencoder</title>
      <link>/publications/dae/</link>
      <pubDate>Sat, 30 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/publications/dae/</guid>
      <description>Abstract A strengthened autoencoder formed by placing an object detector upstream of a decoder is here developed in the context of the model-helped human analysis of composed ornaments from a dictionary of vignettes. The detection part is in charge to detect regions of interest containing some vignette features, and the decoding part to ensure vignette reconstruction with a relative quality depending on feature match. Images of ornaments without typographical composition are generated in order to properly assess the performance of each of the two parts.</description>
    </item>
    
    <item>
      <title>IoU Losses</title>
      <link>/blog/iouloss/</link>
      <pubDate>Sun, 27 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/iouloss/</guid>
      <description>Loss Functions for Object Detection</description>
    </item>
    
  </channel>
</rss>
